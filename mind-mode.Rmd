# Mindless Modeling (TODO) {#mind-mod}

## Features

<!--

```{r eval = FALSE}
library(tidymodels)
library(tidyr)
library(ggplot2)
set.seed(123)

# set up data ----
n <- 2000
df <-
data.frame(
  x1 = runif(n),
  x2 = runif(n),
  x3 = runif(n)
)
df$y1 <- 10*df$x1 + rnorm(n)
df$y2 <- 10*(df$x1)**2 + rnorm(n)
df$y3 <- 10*(df$x1 / df$x2) + rnorm(n)
df$y4 <- df$y3 + 0.5*df$x3

df_test <- df[1001:2000,]
df <- df[1:1000,]

# model fits ----
lr <- 
  linear_reg() %>%
  set_engine("lm") %>%
  set_mode("regression")
dt <- 
  decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("regression")
rf <- 
  rand_forest() %>%
  set_engine("randomForest") %>%
  set_mode("regression")
models <- list(lr, dt, rf)
formulas <- list(
  y1 ~ x1,
  y1 ~ I(x1**2),
  y2 ~ x1,
  y2 ~ I(x1**2),
  y3 ~ x1 + x2,
  y3 ~ I(x1/x2),
  y4 ~ x1 + x2 + x3,
  y4 ~ I(x1/x2) + x3
)
fml_target <- vapply(formulas, function(x) as.character(eval(x)[[2]]), character(1))
fml_rhs <- vapply(formulas, function(x) paste(labels(terms(x)), collapse = " + "), character(1))

formulas_df <- tibble(
  formulas = formulas, 
  target = fml_target,
  formula_desc = fml_rhs
)
models_df <- tibble(
  model_desc = factor(c("linear", "decision tree", "random forest"),
                      levels = c("linear", "decision tree", "random forest")),
  models = models
)
targets_df <- tibble(
  target = paste0("y", 1:4),
  target_true_spec = c("linear", "quadratic", "ratio", "ratio plus linear")
)

# model predictions ----
models_formulas_fits <-
tidyr::crossing(models_df, formulas_df) %>%
  left_join(targets_df, by = "target") %>%
  rowwise() %>%
  mutate(
    target = as.character(eval(formulas)[[2]]),
    fits = list(fit(models, formulas, data = df)),
    preds = list(predict(fits, new_data = df_test)[[".pred"]]),
    mse = sqrt(sum(preds - df_test[[target]])**2)
    )

models_formulas_fits <- 
    models_formulas_fits %>%
    group_by(model_desc) %>%
    mutate(mse_factor = mse / min(mse))

# plot results ----
ggplot(data = models_formulas_fits) +
  aes(x = model_desc, y = mse, col = formula_desc) +
  geom_point() + 
  facet_wrap(target_true_spec ~ ., ncol = 1, scales = "free") +
  theme(
    axis.title = element_blank()
  )
```

```{r eval = FALSE}
tree_rec <- recipe(x = df, formula = y1 ~ x1)

tune_spec <- rand_forest(
  mtry = tune(),
  trees = 1000,
  min_n = tune()
) %>%
  set_mode("regression") %>%
  set_engine("ranger")

tune_wf <- 
  workflow() %>%
  add_recipe(tree_rec) %>%
  add_model(tune_spec)

set.seed(123) 
trees_fold <- vfold_cv(df)

set.seed(456)
tune_res <- tune_grid(
  tune_wf,
  resamples = trees_fold,
  grid = 20
)

final_rf <-
  finalize_model(
    tune_spec,
    select_best(tune_res, metric = "rmse")
  )

final_res <-
  final_rf %>%
  set_engine("ranger", importance = "permutation") %>%
  fit(formula = y1 ~ x1, data = df)

predict(final_res, new_data = df_test)
```

--> 

## Targets

## Evaluation Metrics 

## Clustering

## Lifecycle Management

<!--

We talk about the _FOO_ method\index{FOO} in this chapter.

## Chosing the right target

How you chose to model depends not just on your target variable and the relationships in your data but also the question to be answered. For example, [@murray2020] describes how the "best" approach to forecasting case growth in a pandemic varies depending on whether the goal is to plan population-level interventions and policies or organize short-term hospital capacity.

## Developing meaningful features



## Selecting an algorithm

## Evaluating the right performance metrics

## Strategies

-->
